import Foundation
import Speech
import AVFoundation

class SpeechRecognizerManager: NSObject, ObservableObject, SFSpeechRecognizerDelegate {
    private let audioEngine = AVAudioEngine()
    private var speechRecognizer: SFSpeechRecognizer?
    private var recognitionRequest: SFSpeechAudioBufferRecognitionRequest?
    private var recognitionTask: SFSpeechRecognitionTask?
    private var isRecording = false
    private var error216Count = 0
    private let maxError216Retries = 2
    private var lastError216Time: Date?
    private let error216Cooldown: TimeInterval = 5.0
    
    var onTranscriptionUpdate: ((String) -> Void)?
    var onError: ((String) -> Void)?
    var onPermissionStatus: ((SFSpeechRecognizerAuthorizationStatus) -> Void)?
    var onTranscriptionComplete: ((String) -> Void)?
    
    private var lastTranscription: String = ""
    
    override init() {
        super.init()
        setupSpeechRecognizer()
        requestPermissions()
    }
    
    private func setupSpeechRecognizer() {
        speechRecognizer = SFSpeechRecognizer(locale: Locale(identifier: "es-MX"))
        speechRecognizer?.delegate = self
    }
    
    private func requestPermissions() {
        SFSpeechRecognizer.requestAuthorization { [weak self] authStatus in
            DispatchQueue.main.async {
                self?.onPermissionStatus?(authStatus)
                switch authStatus {
                case .authorized:
                    print("‚úÖ Permiso de reconocimiento de voz concedido")
                case .denied:
                    print("‚ùå Permiso de reconocimiento de voz denegado")
                case .restricted:
                    print("‚ö†Ô∏è Reconocimiento de voz restringido")
                case .notDetermined:
                    print("‚ùì Permiso de reconocimiento de voz no determinado")
                @unknown default:
                    print("‚ùì Estado de permiso desconocido")
                }
            }
        }
    }
    
    func startRecognition() throws {
        print("üéôÔ∏è Iniciando reconocimiento de voz...")
        
        // Verificar disponibilidad del reconocedor
        guard let recognizer = speechRecognizer, recognizer.isAvailable else {
            throw NSError(domain: "SpeechRecognizer", code: 1, userInfo: [NSLocalizedDescriptionKey: "El reconocimiento de voz no est√° disponible"])
        }
        
        // Verificar cooldown del error 216
        if let lastErrorTime = lastError216Time {
            let timeSinceLastError = Date().timeIntervalSince(lastErrorTime)
            if timeSinceLastError < error216Cooldown {
                throw NSError(domain: "SpeechRecognizer", code: 2, userInfo: [NSLocalizedDescriptionKey: "Por favor, espera unos segundos antes de intentar de nuevo"])
            }
        }
        
        // Limpiar sesi√≥n anterior
        cleanupPreviousSession()
        
        // Configurar sesi√≥n de audio
        let audioSession = AVAudioSession.sharedInstance()
        try audioSession.setCategory(.record, mode: .measurement, options: .duckOthers)
        try audioSession.setActive(true, options: .notifyOthersOnDeactivation)
        
        // Crear nueva solicitud de reconocimiento
        recognitionRequest = SFSpeechAudioBufferRecognitionRequest()
        guard let recognitionRequest = recognitionRequest else {
            throw NSError(domain: "SpeechRecognizer", code: 3, userInfo: [NSLocalizedDescriptionKey: "No se pudo crear la solicitud de reconocimiento"])
        }
        
        recognitionRequest.shouldReportPartialResults = true
        recognitionRequest.taskHint = .dictation
        
        // Configurar grabaci√≥n de audio
        let inputNode = audioEngine.inputNode
        let recordingFormat = inputNode.outputFormat(forBus: 0)
        
        // Asegurarse de que no haya tap previo
        inputNode.removeTap(onBus: 0)
        
        // Instalar nuevo tap
        inputNode.installTap(onBus: 0, bufferSize: 1024, format: recordingFormat) { [weak self] buffer, _ in
            self?.recognitionRequest?.append(buffer)
        }
        
        // Iniciar motor de audio
        audioEngine.prepare()
        try audioEngine.start()
        isRecording = true
        print("‚úÖ Motor de audio iniciado correctamente")
        
        // Configurar tarea de reconocimiento
        recognitionTask = recognizer.recognitionTask(with: recognitionRequest) { [weak self] result, error in
            guard let self = self else { return }
            
            if let error = error {
                print("‚ùå Error en reconocimiento: \(error.localizedDescription)")
                
                if let nsError = error as NSError? {
                    if nsError.domain == "kAFAssistantErrorDomain" && nsError.code == 216 {
                        self.handleError216()
                        return
                    }
                }
                
                // Solo mostrar error si no es por falta de habla
                if !(error.localizedDescription.contains("no speech detected") || 
                     error.localizedDescription.contains("no speech found")) {
                    self.onError?("Error en el reconocimiento: \(error.localizedDescription)")
                }
                return
            }
            
            // Verificar si hay resultado antes de procesarlo
            guard let result = result else {
                print("‚ÑπÔ∏è No se detect√≥ habla")
                return
            }
            
            let transcription = result.bestTranscription.formattedString
            if !transcription.isEmpty {
                print("üìù Texto transcrito: \(transcription)")
                self.lastTranscription = transcription
                self.onTranscriptionUpdate?(transcription)
            }
            
            // Reset error counter on successful transcription
            self.error216Count = 0
            
            if result.isFinal {
                print("‚úÖ Transcripci√≥n finalizada")
                if !self.lastTranscription.isEmpty {
                    self.onTranscriptionComplete?(self.lastTranscription)
                }
                self.stopRecognition()
            }
        }
    }
    
    private func handleError216() {
        error216Count += 1
        lastError216Time = Date()
        
        print("‚ö†Ô∏è Error 216 detectado (intento \(error216Count)/\(maxError216Retries))")
        
        if error216Count >= maxError216Retries {
            print("‚ùå M√°ximo de intentos alcanzado para error 216")
            onError?("El reconocimiento de voz no est√° disponible en este momento. Por favor, intenta m√°s tarde.")
            stopRecognition()
            return
        }
        
        // Esperar antes de reintentar
        DispatchQueue.main.asyncAfter(deadline: .now() + error216Cooldown) { [weak self] in
            guard let self = self else { return }
            if self.isRecording {
                print("üîÑ Reintentando despu√©s del cooldown...")
                self.cleanupPreviousSession()
                try? self.startRecognition()
            }
        }
    }
    
    func stopRecognition() {
        print("‚èπÔ∏è Deteniendo reconocimiento...")
        
        // Marcar el final de la grabaci√≥n
        recognitionRequest?.endAudio()
        
        // Detener motor de audio
        if audioEngine.isRunning {
            audioEngine.stop()
            audioEngine.inputNode.removeTap(onBus: 0)
        }
        
        // Finalizar reconocimiento
        recognitionTask?.cancel()
        
        // Limpiar referencias
        recognitionRequest = nil
        recognitionTask = nil
        
        isRecording = false
        print("‚úÖ Sesi√≥n limpiada")
    }
    
    private func cleanupPreviousSession() {
        print("üßπ Limpiando sesi√≥n anterior...")
        
        // Marcar el final de la grabaci√≥n anterior si existe
        recognitionRequest?.endAudio()
        
        // Detener motor de audio
        if audioEngine.isRunning {
            audioEngine.stop()
            audioEngine.inputNode.removeTap(onBus: 0)
        }
        
        // Finalizar reconocimiento
        recognitionTask?.cancel()
        
        // Limpiar referencias
        recognitionRequest = nil
        recognitionTask = nil
        
        print("‚úÖ Sesi√≥n limpiada")
    }
    
    // MARK: - SFSpeechRecognizerDelegate
    
    func speechRecognizer(_ speechRecognizer: SFSpeechRecognizer, availabilityDidChange available: Bool) {
        print("üîÑ Disponibilidad del reconocedor cambiada: \(available ? "Disponible" : "No disponible")")
        if !available && isRecording {
            onError?("El reconocimiento de voz ya no est√° disponible")
            stopRecognition()
        }
    }
}
